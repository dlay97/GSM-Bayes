# -*- coding: utf-8 -*-
"""
Created on Wed Jul 12 15:11:18 2023

@author: 1josh
"""

# import surmise
from surmise.emulation import emulator
from surmise.calibration import calibrator

import numpy as np
import scipy.stats as sps
import sys, os
import shutil
import subprocess
import pandas as pd

import multiprocessing as mp
import time

# Returns dimensions of list of lists
def dim(a):
    if not type(a) == list:
        return []
    return [len(a)] + dim(a[0])

def count_directories(directory):
    count = 0
    for item in os.listdir(directory):
        item_path = os.path.join(directory, item)
        if os.path.isdir(item_path):
            count += 1
    return count

# For reading and formatting data
def read_data(fileName_):
    '''
    given a file name, reads the file line-by-line saving each line as a string. List of strings contains all lines in file with each line being one element in the list.

    Returns list of lines.
    '''
    lines = []
    # Read data in (store each line as list called "lines")
    with open(fileName_) as fp:
        while True:
            line = fp.readline()
            
            lines.append(line)
            if not line: # End when at end of file (no more lines)
                break
    
    return lines

class processGSM_V2:
    '''
    Taken from Josh's code
    
    The purpose of this class is to have all useful tools for processing data generated by Gamow Shell Model (GSM) code in one place. A list of available functions are provided below (details given in each function):

     - getFiles(): given a file path, collects all files based on desired characters and places them inside a pandas DataFrame.

     - getStateInfo(): given a file (can be from getFiles()), finds the energy and |H.PSI-E.PSI| for each found state
    '''

    def __init__(self):
        self.myFiles = []
        self.dataInfo = pd.DataFrame()

    def getFiles(self,path_,stripChars_=[],replaceChars_=[],splitChars_=[],filterChars_=['']):
        '''
        Get all files in a specified path. Returns all path+file names and additional ID markers which can be specified below:
         - stripChars: list of strings which you would like removed for additional ID purposes
         - replaceChars: list of characters you would like to replace for additional ID purposes. Include the character you'd like to remove with the following list item being the character you'd like to replace it with.
         - splitChars: list of characters you would like to subdivide the file name for additional ID purposes
        
        Example:
            path + file  = '~/testFlow/V0_L1-40o0_5He_3I2-_2020.out'
            stripChars   = ['V0_L1-','_2020.out']
            replaceChars = ['o','.','I','/']
            splitChars   = ['_']
            filterChars  = '.out'

            This will operate on the file 'V0_L1-40o0_5He_3I2-_2020.out' to produce:
             prelim. filter ->  Checks if file name contains '.out'
             1. strip       -> '40o0_5He_3I2-'
             2. replace     -> '40.0_5He_3/2-'
             3. split       -> ['40.0','5He','3/2-']
            The total appended list will be [path+file,'40.0','5He','3/2-'].
        '''
        tempInfo = []
        for root, dirs, files in os.walk(path_):
            for file in files:
                if any([True for ch in filterChars_ if ch not in file]):
                    continue

                temp = file
                if stripChars_: # Checks if list is empty (will pass if list is empty)
                    for r in stripChars_:
                        temp = temp.replace(r,'')
                
                if replaceChars_:# Checks if list is empty (will pass if list is empty)
                    for i in range(0,len(replaceChars_),2):
                        temp = temp.replace(replaceChars_[i],replaceChars_[i+1])
                
                if splitChars_:# Checks if list is empty (will pass if list is empty)
                    for r in splitChars_:
                        temp = temp.split(r)
                
                
                tempFile = os.path.join(root,file) # Combines path and file name to one string
                tempFile = tempFile.replace('\\','/')
                
                # If we had any special characters, we will append the items onto the path list
                if any([stripChars_,replaceChars_,splitChars_]):
                    tempInfo.append([tempFile]+temp)
                else: # If no items, just retain path
                    tempInfo.append(tempFile)

        tempInfo.sort(key=lambda tempInfo: tempInfo[0])
        # If we are trying to strip/replace any info from the file name, we'll want to ensure we only save the actual file path from our list (which is actually a list of lists)
        if any(isinstance(el, list) for el in tempInfo):
            self.myFiles = [t[0] for t in tempInfo]
        else: # Otherwise, we simply have a list with only the file path info
            self.myFiles = tempInfo
        self.dataInfo['File Names'] = pd.DataFrame(tempInfo)

    def getStateInfo(self):
        '''
        After using function 'getFiles()', will get information for Complex Energy (E-i\Gamma/2) in MeV and |H.PSI-E.PSI| for each J found in the output files. Will append this data to self.dataInfo so parsed values can be found in the same row as the file name.
        '''
        if not self.myFiles: # If empty file info, stop function
            sys.exit('No files given to read. Please use getFiles() to provide a file list to read from.')
        
        # Loop through all found files
        for i, f in enumerate(self.myFiles):
            # Skip iteration if given file is empty
            if os.stat(f).st_size == 0:
                print('Empty file in: ',f)
                continue

            # Get list of strings with each string being one line
            fLines = read_data(f)

            # Set lists for each complex energy found, its stability, and its J value
            E, HPSI, J = [], [], []

            # Boolean for finding section we're interested in
            foundExpectation = False
            for line in fLines:
                # End search if MPI error is detected
                if 'MPI process' in line:
                    print('Found MPI Error: ',line)
                    break

                # Once we get to the summary of the converged results, set our boolean
                # to true to start searching for our desired quantities
                if 'Expectation values' in line:
                    foundExpectation = True
                    continue
                # elif ('Configuration' in line or 'Spectrum' in line) and foundExpectation:
                #     foundExpectation = False
                #     continue

                if foundExpectation:
                    # Get |H.PSI - E.PSI| from line in section
                    if '|H.PSI - E.PSI|' in line:
                        # Eliminate extra characters
                        temp = line.replace('|H.PSI - E.PSI|oo = ','')
                        temp = temp.replace('\n','')

                        # Convert remaining number to float
                        HPSI.append(float(temp))
                    # Find energy section
                    elif 'E:' in line:
                        # Delimiter to distinguish E from J in same line
                        temp = line.replace('J Pi:',',')
                        
                        # List of characters to remove from our line
                        dropChars = ['E:(',')',' ','\n']
                        for j in dropChars:
                            temp = temp.replace(j,'')
                        
                        # Split our line based on Re(E), Im(E), and J Pi
                        tempList = temp.split(',')

                        # Save complex energy
                        E.append(float(tempList[0])+ float(tempList[1])*1j)

                        # Save J Pi value
                        J.append(tempList[2])

                        # Reset boolean to continue search for next state (if available)
                        foundExpectation = False
            
            if J: # Only do if J is not empty, i.e. we found a state in the output file
                for iJ, j in enumerate(J):
                    eName = 'E('+j+') MeV'
                    hPsiName = 'HPSI '+j

                    self.dataInfo.loc[i,eName] = E[iJ]
                    self.dataInfo.loc[i,hPsiName] = HPSI[iJ]

def toEandGamma(eTilde):
    # Returns Energy and Gamma given a complex energy \tilde{E}
    return np.real(eTilde), -2*np.imag(eTilde)

class Prior:
    def lpdf(theta):
        ret = np.zeros(theta.shape[0])
        for i in range(len(paramMeans)):
            toAdd = sps.norm.logpdf(theta[:,i],paramMeans[i],paramStds[i])
            ret += toAdd
            
        return ret.reshape((-1,1))
    
    def rnd(n):
        ret = np.zeros((n,len(paramMeans)))
        for i in range(len(paramMeans)):
            ret[:,i] = sps.norm.rvs(loc=paramMeans[i],scale=paramStds[i],
                                    size=n)
        return ret

def setup_gsm(theta,dirForWorkspace):
    os.makedirs(dirForWorkspace,exist_ok=True)
    os.makedirs(os.path.join(dirForWorkspace,'workspace'),exist_ok=True)
    for i in range(gsmCPUs):
        os.makedirs(os.path.join(dirForWorkspace,'workspace','node_'+str(i)),exist_ok=True)

    # For all our input files given theta, set the proper parameters
    replaceDict = {"$GSM_NODES":gsmNodes, "$GSM_CPUS":gsmCPUs,
                    "$L1_dn":theta[0], "$L1_r0n":theta[1],
                    "$L1_v0n":theta[2], "$L1_vson":theta[3],
                    "$L1_dp":theta[4], "$L1_r0p":theta[5],
                    "$L1_v0p":theta[6], "$L1_vsop":theta[7],
                    "$Vc10":theta[8], "$Vc00":theta[9],
                    "$Vc01":theta[10], "$Vt10":theta[11]}
    
    # Create an empty list to put our input file names into as we make them
    inputNameList = []
    # Define path to get to template directory
    templateDir = os.path.join(originalDir,'templates')

    # Loop through all templates in our templateNames list
    for tempName in templateNames:
        # Open our template and read each line into a list
        with open(os.path.join(templateDir,tempName)) as temp:
            fileTemplate = temp.readlines()
        
        # Create input file name by generic process template_5He_Mao2020
        inputName = tempName.replace('template','input')
        inputName = inputName.replace('.temp','.dat')
        inputNameList.append(inputName)
        
        # Open our input file as write
        with open(os.path.join(dirForWorkspace,inputName),'w') as f:
            # Loop through each input template line
            for line in fileTemplate:
                # loop through each dictionary item name 'key'
                for key, value in replaceDict.items():
                    # Replace the current dictionary item with its value
                    line = line.replace(key, str(value))
                f.write(line)
    return inputNameList, replaceDict

def run_gsm(di,inputNames):
    shutil.copy('GSM_exe',di)
    os.chdir(di)

    # Run GSM for each found input name
    for inName in inputNames:
        outName = inName.replace('input','output')
        subprocess.run('mpirun -np {} -map-by node -bind-to none ./GSM_exe <{} > {}'.format(gsmNodes,inName,outName),
                       shell=True)
        
    os.chdir(originalDir)
    os.remove(os.path.join(di,'GSM_exe'))
    return None
    
# def model(x,params,runFolder): # For Serial
def model(myItems): # For multiprocessing
    """
    x is a dummy argument b/c surmise expects it. If we were to calibrate to multiple
    nuclei, x might be (N,Z). Not quite - surmise can get by on a 1D array (I'm not
    sure how it handles D-dimensional data). So, Kyle and friends use it as an index
    for the observations
    """
    index, x, params, runFolder = myItems
    # modelOut = np.zeros((params.shape[0],6))
    print('Working on dataset {}'.format(index))
    # Index of the folder the current process will run in
    newIter = index
    di = os.path.join(runFolder,str(newIter).zfill(6))
    
    # Setup our GSM input files from the 'templates' folder
    inputNames, thetaDict = setup_gsm(params,di)
    # Run calculations for each GSM input file
    run_gsm(di,inputNames)
    
    # Call class to handle GSM outputs
    gsm = processGSM_V2()

    # Get all files with the prefix 'output'
    gsm.getFiles(di,filterChars_=['output'])

    # From found output files, get E, HPSI data for each J as a DataFrame
    gsm.getStateInfo()

    # Get a list of all energy columns in DataFrame
    enegCols = [col for col in gsm.dataInfo.columns if 'E' in col]
    
    # Get directory names to find nucleus name
    dirNames = gsm.dataInfo['File Names'].to_list()

    # We want to keep track of our energies and their corresponding nucleus
    # and J pi value, so we introduce nucState to build a list which will eventually
    # become the headers for the modelVals csv file.
    nucState = []
    # Append directory name to each energy so that we have an energy for each nucleus
    # note many of these might be blank in the csv as 5He only has 3/2- so any column
    # with J^Pi=0+ for example will return NaN or blank values
    for dn in dirNames:
        for ec in enegCols:
            nucState.append(dn+ec)
    # Strip extra characters from the directory name and file name to match the expected formats
    removeChars = [di+'/','output_','_Mao2020.dat','E',' MeV']
    for rc in removeChars:
        nucState = [c.replace(rc,'') for c in nucState]

    # Get our energy datasets as a long numpy array
    npEnegData = gsm.dataInfo[enegCols].to_numpy().flatten()
    eneg, gamma = toEandGamma(npEnegData)
    # Find the results which have Nan and set their \Gammas to be NaN too
    nanIndex = np.isnan(eneg)
    gamma[nanIndex] = np.nan

    # Save nucleus and state names with prefixes E and G so we know energy and decay widths
    nucStateE = np.char.add('E', np.array(nucState))
    nucStateG = np.char.add('G', np.array(nucState))
    modelOutNames = list(np.vstack((nucStateE, nucStateG)).T.flatten())
    # Save model outputs to be in the same format as our yMeans
    # modelOut = np.array([E_0,Gamma_0,E_1,Gamma_1,...,E_n,Gamma_n])
    modelOut = np.vstack((eneg, gamma)).T.flatten()
    
    # Convert everything from MeV to keV
    return 1000*modelOut, modelOutNames, thetaDict

#%% Main Run
# Main run code

#Parameters from Mao's paper
paramMeans = np.array([0.63,2.15,39.5,10.7,
                       0.64,2.06,42.1,11.1,
                       -8.309,-8.895,-9.425,-22.418])
paramStds = np.array([0.02,0.04,0.2,0.2,
                      0.02,0.04,0.4,0.5,
                      0.07,0.09,1.130,0.970])

# Names of all template files you wish to use 
# These specify the nuclei of interest and their states
templateNames = ['template_5He_Mao2020.temp','template_5Li_Mao2020.temp',
                  'template_6Be_Mao2020.temp','template_6He_Mao2020.temp',
                  'template_6Li_Mao2020.temp']

# Experimental data from NNDC (it's S_n and NNDC Gamma error)
# The ordering is [E_0,Gamma_0,E_1,Gamma_1,...,E_n,Gamma_n] 
yMean = np.array([735.,600,1970.,1230,            # 5He, 5Li
                  1372.,92,3042.,1160,            # 6Be (0+, 2+)
                  -975.,0,822.,113,               # 6He (0+, 2+)
                  -3698.,0,-1512.,24,             # 6Li (1+_0 3+_0)
                  -135.1,8.2*10**-3,614,1.3*10**3, # 6Li (0+_0 2+_0)
                  1677.,541,1952,1.3*10**3])      # 6Li (2+_1 1+_1)
minStdVal = 1E-6 # Since surmise can't handle anything less than this value, we pass it in as a minimum instead of 0
yStd = np.array([20,20,50,50,         # 5He, 5Li
                 9,6,50,60,           # 6Be (0+, 2+)
                 9,minStdVal,5,20,            # 6He (0+, 2+)
                 3,minStdVal,2,2,             # 6Li (1+_0 3+_0)
                 0.1,2*10**-3,22,100, # 6Li (0+_0 2+_0)
                 15,20,50,200])       # 6Li (2+_1 1+_1)

# GSM code emulation information
# For parallelization
gsmNodes = 2
gsmCPUs = 14
totalResourcesGSM = gsmNodes * gsmCPUs
totalCPUs = mp.cpu_count() # get available number of CPUs

nSamples = 10 # Total number of emulation dataset samples

# For parallelizing emulation process, we divide up remaining nodes from that requested
emuCPUs = int(totalCPUs / totalResourcesGSM)

emuFolder = 'emulator-runs' # Folder to save the emulation data

originalDir = os.getcwd() # Get main directory this code runs in

emulatorDir = os.path.join(originalDir,emuFolder) # Identify emulation folder path

# Make emulator-runs folder if it doesn't exist
os.makedirs(emulatorDir,exist_ok=True)

'''
Since we're generating data for emulation, we don't need to worry about
existing data. We will just run and overwrite things each time this script
is called.
'''
# For timing if you'd like and are a nerd about that sort of thing
start = time.time()

print('Not enough data for requested emulator, running {} high-fidelity calculations'.format(nSamples))
print('{} Total CPUs available'.format(totalCPUs))
print('Each GSM calculation is using {} CPUs and {} Nodes'.format(gsmCPUs,gsmNodes))
print('Running {} sets of calculations in parallel'.format(emuCPUs))

# Get desired number of random theta values based on number of samples requested
thetaTest = Prior.rnd(nSamples)
modelVals = [] # Stores all high-fidelity model outputs
modelNucNames = [] # Stores names of each energy and decay width stored in modelVals
modelThetas = [] # Stores each theta parameter set to be converted to dataframe when exporting to csv

# Parallel (multiprocessing)
# For multiprocessing, we need to input only one variable to our function,
# so we put everything in a tuple!
items = [(i,[],tTest,emuFolder) for i, tTest in enumerate(thetaTest)]

# Run in parallel based on number of CPUs available
with mp.Pool(emuCPUs) as pool:
    for result in pool.map(model,items):
        modelVals.append(result[0]) # Save each parallelized list result
        modelNucNames = result[1] # Save each parallelized list result
        modelThetas.append(result[2]) # Saves the theta dictionary used in making input files

# We will save our model values based on Nucleus(state) labeling scheme and save to csv
modelVals = pd.DataFrame(np.array(modelVals),columns=modelNucNames)
modelVals.to_csv(os.path.join(emulatorDir,"summary_model_vals.csv"),index=False)
# Likewise, we will take the theta dictionaries and save as a csv
modelThetas = pd.DataFrame(modelThetas)
modelThetas.to_csv(os.path.join(emulatorDir,"summary_model_thetas.csv"),index=False)

end = time.time()
print("Total high-fidelity runtime = ",end - start)

'''
Once this script is complete (using large numbers of samples and CPUs) we
can be sure to send the data back to another machine you'd prefer to work on
(like a laptop). From there you can simply run the bayesian_run.py code
to perform emulator construction, bayesian callibration, and finally plotting
a corner plot.
'''
